{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jctorch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import ViTImageProcessor, ViTForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViTImageProcessor.from_pretrained('./vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('./vit-base-patch16-224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86,567,656 total parameters.\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying low rank on vit.encoder.layer.0.attention.attention.query\n",
      "applying low rank on vit.encoder.layer.0.attention.attention.key\n",
      "applying low rank on vit.encoder.layer.1.attention.attention.query\n",
      "applying low rank on vit.encoder.layer.1.attention.attention.key\n",
      "applying low rank on vit.encoder.layer.2.attention.attention.query\n",
      "applying low rank on vit.encoder.layer.2.attention.attention.key\n",
      "applying low rank on vit.encoder.layer.3.attention.attention.query\n",
      "applying low rank on vit.encoder.layer.3.attention.attention.key\n",
      "applying low rank on vit.encoder.layer.4.attention.attention.query\n",
      "applying low rank on vit.encoder.layer.4.attention.attention.key\n",
      "applying low rank on vit.encoder.layer.5.attention.attention.query\n",
      "applying low rank on vit.encoder.layer.5.attention.attention.key\n",
      "applying low rank on vit.encoder.layer.6.attention.attention.query\n",
      "applying low rank on vit.encoder.layer.6.attention.attention.key\n",
      "applying low rank on vit.encoder.layer.7.attention.attention.query\n",
      "applying low rank on vit.encoder.layer.7.attention.attention.key\n",
      "applying low rank on vit.encoder.layer.8.attention.attention.query\n",
      "applying low rank on vit.encoder.layer.8.attention.attention.key\n",
      "applying low rank on vit.encoder.layer.9.attention.attention.query\n",
      "applying low rank on vit.encoder.layer.9.attention.attention.key\n",
      "applying low rank on vit.encoder.layer.10.attention.attention.query\n",
      "applying low rank on vit.encoder.layer.10.attention.attention.key\n",
      "applying low rank on vit.encoder.layer.11.attention.attention.query\n",
      "applying low rank on vit.encoder.layer.11.attention.attention.key\n"
     ]
    }
   ],
   "source": [
    "import low_rank\n",
    "\n",
    "model_lr = low_rank.ModuleLowRank(compress_ratio=2.0, \n",
    "                                name_omit=['norm', 'head', 'patch_embed', 'downsample'],\n",
    "                                name_include= ['query', 'key'], \n",
    "                                is_approximate=True)\n",
    "\n",
    "model = model_lr(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79,489,768 parameters, compression ratio 0.9182\n"
     ]
    }
   ],
   "source": [
    "params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{params:,} parameters, compression ratio {params/total_params:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vit-base-patch16-224-svd-QK/preprocessor_config.json']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'vit-base-patch16-224-svd-QK'\n",
    "model.save_pretrained(model_name)\n",
    "processor.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jctorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
