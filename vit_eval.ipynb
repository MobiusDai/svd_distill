{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from custom_dataset import ImageNet1K\n",
    "from dataset.classes import IMAGENET2012_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViTImageProcessor.from_pretrained('./vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('./vit-base-patch16-224')\n",
    "\n",
    "model = model.to('cuda')\n",
    "model.eval()\n",
    "print('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate param\n",
    "param = sum(p.numel() for p in model.parameters())\n",
    "print(f'Param: {param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = ImageNet1K(image_path='./dataset/val_data/', labels=IMAGENET2012_CLASSES, transform=processor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in val_loader:\n",
    "    print(batch[0]['pixel_values'].shape)\n",
    "    print(batch[1])\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(batch[0]['pixel_values'].squeeze(1).to('cuda')).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the accuracy of vision transformer\n",
    "accurate = 0\n",
    "count = 0\n",
    "\n",
    "for i, batch in enumerate(val_loader):\n",
    "    image = batch[0]['pixel_values'].squeeze(1).to('cuda')\n",
    "    label = batch[1].to('cuda')\n",
    "    pred = model(image).logits.argmax(dim=1)\n",
    "    \n",
    "    accurate += (pred == label).sum()\n",
    "    count += image.shape[0]\n",
    "    \n",
    "    if i and i % 20 == 0:\n",
    "        print(f'step {i}/ {len(val_loader)}, accuracy: {accurate/count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jctorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
